{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11404896,"sourceType":"datasetVersion","datasetId":7143728}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"899f2585-ded0-4674-8181-7442bc36b7c5","cell_type":"markdown","source":"### Importing Necessary Libraries, Setting Seed and Device\n\nThe below code imports the required libraries for the running of this notebook. Further we set seed to 42 to maintain consistency or reproducibility and set devide to cuda (if available)","metadata":{}},{"id":"2dca7389-1649-441e-b09a-ed9b992a587b","cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom transformers import BertTokenizer, BertModel\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import precision_recall_fscore_support, classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nimport random\n\nrandom.seed(42)\nnp.random.seed(42)\ntorch.manual_seed(42)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(42)\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\nDATA_PATH = '/kaggle/input/partc-data/partc_data.csv' # we used this path in kaggle. please change to whichever path partc_data.csv is stored in accordingly","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T17:23:52.795704Z","iopub.execute_input":"2025-04-14T17:23:52.795998Z","iopub.status.idle":"2025-04-14T17:23:52.803406Z","shell.execute_reply.started":"2025-04-14T17:23:52.795979Z","shell.execute_reply":"2025-04-14T17:23:52.802738Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":4},{"id":"4858062d-77d1-45a4-9278-4ab70cf34b51","cell_type":"markdown","source":"### Defining the BERT-based classifier model\n\n\n#### ***CaptionClassifier (model class)***\nBERT-based classifier for identifying which model generated a caption. The constructor initializes the BERT model, dropout and additional classifier layers which we will be fine-tuning on our dataset from Part-B\n\n\nforward() method returns the model **output logits**.\n\n","metadata":{}},{"id":"05f1d0dc-5622-43cb-8f90-9ead1944481c","cell_type":"code","source":"# BERT-based classifier model\nclass CaptionClassifier(nn.Module):\n    def __init__(self, bert_model_name=\"bert-base-uncased\", dropout_rate=0.1):\n        super(CaptionClassifier, self).__init__()\n        \n        self.bert = BertModel.from_pretrained(bert_model_name)\n        \n        bert_hidden_size = self.bert.config.hidden_size # output dim from BERT\n\n        # adding classifier layers\n        self.dropout = nn.Dropout(dropout_rate)\n        self.classifier = nn.Sequential(\n            nn.Linear(bert_hidden_size, 256),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(256, 2),\n            nn.Softmax(dim=1)\n        )\n    \n    def forward(self, input_ids, attention_mask, token_type_ids=None):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n        \n        # use the [CLS] token embedding (first token)\n        pooled_output = outputs.pooler_output\n        pooled_output = self.dropout(pooled_output)\n        \n        probs = self.classifier(pooled_output)\n        \n        return probs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T17:23:55.691337Z","iopub.execute_input":"2025-04-14T17:23:55.691827Z","iopub.status.idle":"2025-04-14T17:23:55.697302Z","shell.execute_reply.started":"2025-04-14T17:23:55.691802Z","shell.execute_reply":"2025-04-14T17:23:55.696598Z"}},"outputs":[],"execution_count":5},{"id":"d308032a-354d-4ccb-a74f-b405695ceec7","cell_type":"markdown","source":"### Defining the CaptionDataset class to process data\n\n\n#### ***CaptionDataset (Dataset class)***\nHere we process the data that is input as a dataframe. The ground-truth captions, generated captions and perturbation (occlusion percentage) are to be input to the BERT classifier as:\n\n> \\<original_caption> \\<SEP> \\<generated_caption> \\<SEP> \\<perturbation_percentage>\n\n\n**A: smolvlm** \n\n**B: custom model - CLIP-ViT encoder + GPT2 decoder + contrastive loss**\n","metadata":{}},{"id":"200f7a12-e8b7-484e-85bd-d2658318be90","cell_type":"code","source":"# To process the data from csv into a Dataset object for data-loading\nclass CaptionDataset(Dataset):\n    def __init__(self, data_df, tokenizer, max_length=512):\n        self.data_df = data_df\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.data_df)\n    \n    def __getitem__(self, idx):\n        row = self.data_df.iloc[idx]\n        \n        original_caption = str(row['original_caption'])\n        generated_caption = str(row['generated_caption'])\n        perturbation = str(row['perturbation_percentage'])\n        \n        # Input Text: <original_caption> <SEP> <generated_caption> <SEP> <perturbation_percentage>\n        input_text = original_caption + \" \" + self.tokenizer.sep_token + \" \" + generated_caption + \" \" + self.tokenizer.sep_token + \" \" + perturbation\n        \n        \n        encoding = self.tokenizer(input_text, add_special_tokens=True, max_length=self.max_length, padding='max_length', truncation=True, return_tensors='pt')\n        \n        label = row['model_label']\n        if label == 'A':  # Model A is smolvlm\n            label_tensor = torch.tensor([1.0, 0.0], dtype=torch.float)\n        else:  # Model B is our custom model (CLIP-ViT + GPT2 with contrastive loss)\n            label_tensor = torch.tensor([0.0, 1.0], dtype=torch.float)\n        \n        return {\n            'input_ids': encoding['input_ids'].squeeze(),\n            'attention_mask': encoding['attention_mask'].squeeze(),\n            'token_type_ids': encoding['token_type_ids'].squeeze(),\n            'label': label_tensor\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T17:23:58.260424Z","iopub.execute_input":"2025-04-14T17:23:58.260881Z","iopub.status.idle":"2025-04-14T17:23:58.266904Z","shell.execute_reply.started":"2025-04-14T17:23:58.260858Z","shell.execute_reply":"2025-04-14T17:23:58.266350Z"}},"outputs":[],"execution_count":6},{"id":"7030ed73-5d96-436e-b333-188d7e39726a","cell_type":"markdown","source":"### Defining the training function (with validation)\n\n\n#### ***train_classifier (function)***\nBERT-based classifier for identifying which model generated a caption. The constructor initializes the BERT model, dropout and additional classifier layers which we will be fine-tuning on our dataset from Part-B\n\n \nTrains the BERT-based caption classifier.\n- model (nn.Module): Custom image captioning model.\n- dataloader (DataLoader): Training data loader.\n- optimizer: Optimizer (e.g., Adam).\n- criterion (Loss): Loss function.\n- device (str): Device to use ('cuda' or 'cpu').\n- epochs (int): Number of epochs.","metadata":{}},{"id":"4fdaf51c-c045-4448-ba2d-b11258249d67","cell_type":"code","source":"# storing the loss and accuracy metrics here to maintain training history\nhistory = {\n        'train_loss': [],\n        'train_acc': [],\n        'val_loss': [],\n        'val_acc': []\n    }\n\ndef train_classifier(model, train_loader, val_loader, optimizer, criterion, device, epochs=5):\n    # note, we included val_loader as well here since it is required for validatin in between training epochs. This is done in order to store the best model\n    # and to use it for eval finally. You may remove this altogether and just use the train_loader, then use the final saved model to eval.\n    best_val_acc = 0.0\n    \n    for epoch in range(epochs):\n        model.train()\n        train_loss = 0.0\n        train_correct = 0\n        train_total = 0\n        \n        train_progress = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Train]')\n        \n        for batch in train_progress:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            token_type_ids = batch['token_type_ids'].to(device)\n            labels = batch['label'].to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(input_ids, attention_mask, token_type_ids)\n            loss = criterion(outputs, labels)\n            \n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n            \n            pred_classes = torch.argmax(outputs, dim=1)\n            true_classes = torch.argmax(labels, dim=1)\n            train_total += labels.size(0)\n            train_correct += (pred_classes == true_classes).sum().item()\n            \n            train_progress.set_postfix({'loss': train_loss / (train_progress.n + 1), 'accuracy': 100 * train_correct / train_total})\n        \n        avg_train_loss = train_loss / len(train_loader)\n        train_accuracy = 100 * train_correct / train_total\n        history['train_loss'].append(avg_train_loss)\n        history['train_acc'].append(train_accuracy)\n        \n        # validate\n        model.eval()\n        val_loss = 0.0\n        val_correct = 0\n        val_total = 0\n        \n        with torch.no_grad():\n            val_progress = tqdm(val_loader, desc=f'Epoch {epoch+1}/{epochs} [Valid]')\n            \n            for batch in val_progress:\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                token_type_ids = batch['token_type_ids'].to(device)\n                labels = batch['label'].to(device)\n                \n                outputs = model(input_ids, attention_mask, token_type_ids)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                \n                pred_classes = torch.argmax(outputs, dim=1)\n                true_classes = torch.argmax(labels, dim=1)\n                val_total += labels.size(0)\n                val_correct += (pred_classes == true_classes).sum().item()\n                \n                val_progress.set_postfix({'loss': val_loss / (val_progress.n + 1), 'accuracy': 100 * val_correct / val_total})\n        \n        avg_val_loss = val_loss / len(val_loader)\n        val_accuracy = 100 * val_correct / val_total\n        history['val_loss'].append(avg_val_loss)\n        history['val_acc'].append(val_accuracy)\n        \n        print(f'Epoch {epoch+1}/{epochs}:')\n        print(f'  Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%')\n        print(f'  Valid Loss: {avg_val_loss:.4f}, Valid Accuracy: {val_accuracy:.2f}%')\n        \n        if val_accuracy > best_val_acc:\n            best_val_acc = val_accuracy\n            torch.save(model.state_dict(), 'best_bert_caption_classifier.pt')\n            print(f'  New best model saved with validation accuracy: {val_accuracy:.2f}%')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T17:24:01.865436Z","iopub.execute_input":"2025-04-14T17:24:01.866110Z","iopub.status.idle":"2025-04-14T17:24:01.876840Z","shell.execute_reply.started":"2025-04-14T17:24:01.866088Z","shell.execute_reply":"2025-04-14T17:24:01.876226Z"}},"outputs":[],"execution_count":7},{"id":"00b33326-ef52-4b42-9d54-da4f891dc286","cell_type":"markdown","source":"### Defining the evaluation function (testing)\n\n\n#### ***evaluate_classifier (function)***\nEvaluate the classification model.\n- model (nn.Module): Trained model.\n- dataloader (DataLoader): Test data loader.\n- device (str): 'cuda' or 'cpu'.\n\n##### Returns\ndict: Precision, Recall and F1 scores for the test set.\n","metadata":{}},{"id":"47dd5f97-98c8-4462-8b48-3717aa827fbc","cell_type":"code","source":"def evaluate_classifier(model, dataloader, device):\n    model.eval()\n    \n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc='Evaluating'):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            token_type_ids = batch['token_type_ids'].to(device)\n            labels = batch['label'].to(device)\n            \n            outputs = model(input_ids, attention_mask, token_type_ids)\n            \n            pred_classes = torch.argmax(outputs, dim=1)\n            true_classes = torch.argmax(labels, dim=1)\n            \n            all_preds.extend(pred_classes.cpu().numpy())\n            all_labels.extend(true_classes.cpu().numpy())\n    \n    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n    \n    results = {\n        'precision': precision,\n        'recall': recall,\n        'f1': f1\n    }\n    \n    print(classification_report(all_labels, all_preds, target_names=['Model A', 'Model B']))\n    \n    cm = confusion_matrix(all_labels, all_preds)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=['Model A', 'Model B'], \n                yticklabels=['Model A', 'Model B'])\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.tight_layout()\n    plt.savefig('confusion_matrix.png')\n    plt.close()\n    \n    return results\n\ndef plot_training_history(history):\n    plt.figure(figsize=(12, 5))\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(history['train_loss'], label='Train Loss')\n    plt.plot(history['val_loss'], label='Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Training and Validation Loss')\n    plt.legend()\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(history['train_acc'], label='Train Accuracy')\n    plt.plot(history['val_acc'], label='Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.title('Training and Validation Accuracy')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.savefig('training_history.png')\n    plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T17:24:05.256927Z","iopub.execute_input":"2025-04-14T17:24:05.257300Z","iopub.status.idle":"2025-04-14T17:24:05.270028Z","shell.execute_reply.started":"2025-04-14T17:24:05.257265Z","shell.execute_reply":"2025-04-14T17:24:05.269201Z"}},"outputs":[],"execution_count":8},{"id":"a5a1df12-22a6-4b38-805b-9261db9679c7","cell_type":"code","source":"print(\"Loading dataset\")\ndf = pd.read_csv(DATA_PATH)\nprint(f\"Loaded dataset with {len(df)} examples\")\n\nprint(f\"Label distribution: {df['model_label'].value_counts().to_dict()}\")\nprint(f\"Perturbation percentage distribution: {df['perturbation_percentage'].value_counts().to_dict()}\")\n\n# print(\"Loading BERT tokenizer\")\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\ndataset = CaptionDataset(df, tokenizer)\n\n# Split dataset into train, validation, and test sets (70:10:20)\ntotal_size = len(dataset)\ntrain_size = int(0.7 * total_size)\nval_size = int(0.10 * total_size)\ntest_size = total_size - train_size - val_size\n\ntrain_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size],generator=torch.Generator().manual_seed(42))\n\nprint(f\"Dataset split: Train={train_size}, Validation={val_size}, Test={test_size}\")\n\nbatch_size = 32  # this gave a peak GPU memory utilization of around 13.6 GB during training\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)\n\nmodel = CaptionClassifier().to(device)\n\noptimizer = optim.AdamW(model.parameters(), lr=2e-5)\ncriterion = nn.BCELoss()  # using binary cross-entropy\n\nprint(\"Training model...\")\nnum_epochs = 3\ntrain_classifier(model, train_loader, val_loader, optimizer, criterion, device, epochs=num_epochs)\n\nplot_training_history(history)\n\nprint(\"Loading best model for evaluation...\")\nmodel.load_state_dict(torch.load('best_bert_caption_classifier.pt'))\n\nprint(\"Evaluating model on test set...\")\nresults = evaluate_classifier(model, test_loader, device)\n\nprint(\"\\nTest Results:\")\nprint(f\"Precision: {results['precision']:.4f}\")\nprint(f\"Recall: {results['recall']:.4f}\")\nprint(f\"F1 Score: {results['f1']:.4f}\")\n\ntorch.save({'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'tokenizer': tokenizer.__class__.__name__, 'results': results}, 'bert_caption_classifier_model.pt')\n\nprint(\"Model training and evaluation complete. Model saved to 'bert_caption_classifier_model.pt'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T17:24:08.490708Z","iopub.execute_input":"2025-04-14T17:24:08.491316Z","iopub.status.idle":"2025-04-14T17:43:11.958763Z","shell.execute_reply.started":"2025-04-14T17:24:08.491288Z","shell.execute_reply":"2025-04-14T17:43:11.958082Z"}},"outputs":[{"name":"stdout","text":"Loading dataset\nLoaded dataset with 5568 examples\nLabel distribution: {'B': 2784, 'A': 2784}\nPerturbation percentage distribution: {50: 1856, 10: 1856, 80: 1856}\nDataset split: Train=3897, Validation=556, Test=1115\nTraining model...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/3 [Train]: 100%|██████████| 122/122 [05:44<00:00,  2.82s/it, loss=0.189, accuracy=93.7]\nEpoch 1/3 [Valid]: 100%|██████████| 18/18 [00:17<00:00,  1.04it/s, loss=0.0203, accuracy=99.8]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3:\n  Train Loss: 0.1885, Train Accuracy: 93.69%\n  Valid Loss: 0.0203, Valid Accuracy: 99.82%\n  New best model saved with validation accuracy: 99.82%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/3 [Train]: 100%|██████████| 122/122 [05:52<00:00,  2.89s/it, loss=0.0157, accuracy=99.8]\nEpoch 2/3 [Valid]: 100%|██████████| 18/18 [00:17<00:00,  1.03it/s, loss=0.0134, accuracy=99.8]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/3:\n  Train Loss: 0.0157, Train Accuracy: 99.77%\n  Valid Loss: 0.0134, Valid Accuracy: 99.82%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/3 [Train]: 100%|██████████| 122/122 [05:53<00:00,  2.90s/it, loss=0.0153, accuracy=99.7] \nEpoch 3/3 [Valid]: 100%|██████████| 18/18 [00:17<00:00,  1.03it/s, loss=0.0132, accuracy=99.8]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/3:\n  Train Loss: 0.0153, Train Accuracy: 99.69%\n  Valid Loss: 0.0132, Valid Accuracy: 99.82%\nLoading best model for evaluation...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/618418794.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('best_bert_caption_classifier.pt'))\n","output_type":"stream"},{"name":"stdout","text":"Evaluating model on test set...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 35/35 [00:34<00:00,  1.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n     Model A       1.00      1.00      1.00       551\n     Model B       1.00      1.00      1.00       564\n\n    accuracy                           1.00      1115\n   macro avg       1.00      1.00      1.00      1115\nweighted avg       1.00      1.00      1.00      1115\n\n\nTest Results:\nPrecision: 0.9973\nRecall: 0.9973\nF1 Score: 0.9973\nModel training and evaluation complete. Model saved to 'bert_caption_classifier_model.pt'\n","output_type":"stream"}],"execution_count":9}]}